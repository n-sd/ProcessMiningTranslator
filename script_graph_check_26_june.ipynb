{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeaxioms(temp_graph_dictionary):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    nodes = \"\"\n",
    "    #for node in range(0, len(temp_graph_dictionary)):\n",
    "    for node in temp_graph_dictionary:\n",
    "        nodes = nodes + \"a\" + str(node[\"Node\"]) + \";\"\n",
    "\n",
    "\n",
    "    nodes = nodes[:-1]\n",
    "    #nodes = \"aS;a0;a1;a2;a3;a4;a5;a6;a7;a8;a9;a10;a11;a12;a13;a14;a15;a16;a17;a18;a19;a20;a21;a22;a23;a24;a25;a26;a27;a28;a29;a30;a31;a32;a33;a34;a35;a36;a37;a38;a39;a40;a41;a42;a43;a44;a45;a46;a47;a48;a49;a50;aF\"\n",
    "\n",
    "    f = open(\"logicalprogram.lp\", \"w\")\n",
    "    f.write(\"\"\"\n",
    "\n",
    "    event(\"\"\" + nodes + \"\"\").\n",
    "    fluent(started(E)) :- event(E).\n",
    "    fluent(completed(E)) :- event(E).\n",
    "    time(1..30).\n",
    "\n",
    "    % definitions\n",
    "    initiates(E, started(E), T) :- happens(E,T), event(E), time(T).\n",
    "    terminates(E, started(E1), T) :- happens(E,T), holdsAt(started(E1),T), event(E), time(T).\n",
    "    initiates(E, completed(E1), T) :- happens(E,T), holdsAt(started(E1), T), event(E), time(T).\n",
    "\n",
    "    holdsAt(F,T) :- happens(E,T1), initiates(E,F,T1), not stoppedIn(T1,F,T), T1<T, time(T), time(T1).\n",
    "    stoppedIn(T1,F,T2) :- happens(E,T), T1<T, T<T2, terminates(E,F,T), time(T), time(T1), time(T2).\n",
    "\n",
    "    % complements\n",
    "    predecesor(E1, E2, T) :- happens(E1,T1), happens(E2, T), T1 = (T-1), time(T), time(T1), event(E1), event(E2).\n",
    "    another(E, T1, T2) :- happens(E, T), T1 < T, T < T2, time(T), time(T1), time(T2), event(E).\n",
    "    bbetween(E1, E2, T) :- happens(E1, T1), happens(E2, T2), happens(E2, T), not another(E1, T1, T), T1 < T2, T2 < T, time(T), time(T1), time(T2), event(E1), event(E2).\n",
    "    \n",
    "    % restrictions\n",
    "\n",
    "    :- happens(E, T), happens(E1, T), event(E), event(E1), E != E1.\n",
    "\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "    f.close()\n",
    "\n",
    "#print(writeaxioms(graph_1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add input constraints for \"or\" function for the graph given to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_sequence(Node, Inputs):\n",
    "    str1 = \":- happens(a\"+str(Node)+\",T), not predecesor(a\"+str(Inputs[0])+\",a\"+str(Node)+\",T), time(T).\"\n",
    "    return str(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_or(Node, Inputs): #node is the node number, inputs is the array of inputs\n",
    "    strN = \":- happens(a\" + str(Node) + \",T), not 1 {\" \n",
    "    for input in Inputs:\n",
    "        strN = strN + \"predecesor(a\"+ str(input) + \",a\" + str(Node) + \",T); \"   \n",
    "    \n",
    "    strN = strN[:-2]\n",
    "    strN = strN + \"}.\"\n",
    "    return str(strN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addinputsOR(temp_graph_dictionary):\n",
    "    for node in temp_graph_dictionary:\n",
    "            if len(node[\"Inputs\"]) == 0: #in case there are no inputs, it must be the starting node or a node without inputs\n",
    "                #print(\"no inputs to \" + str(node[\"Node\"]) + \" from \" + str(node[\"Inputs\"])  )\n",
    "                #print(node[\"Inputs\"])\n",
    "                unusedvariable = 0\n",
    "            if len(node[\"Inputs\"]) == 1:\n",
    "                f = open(\"logicalprogram.lp\", \"a\")\n",
    "                f.write(function_sequence(node[\"Node\"], node[\"Inputs\"]) + \"\\n\")\n",
    "                f.close()\n",
    "            if len(node[\"Inputs\"]) >= 2:\n",
    "                f = open(\"logicalprogram.lp\", \"a\")\n",
    "                f.write(function_or(node[\"Node\"], node[\"Inputs\"]) + \"\\n\")\n",
    "                f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add the sequence based on the input sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addsequencefromlist(i):\n",
    "    sequence = \"\\n\"+ \"\\n\"+ \"\\n\" + \"% sequence\" + \"\\n\"+ \"\\n\"\n",
    "    node = 0\n",
    "    #print(\"current sequence: \", i)\n",
    "    for action in i:\n",
    "        node = node + 1\n",
    "        sequence = sequence + \"happens(a\"+str(action)[1:]+\",\"+str(node)+\").\"  + \"\\n\"\n",
    "    f = open(\"logicalprogram.lp\", \"a\")\n",
    "    f.write(sequence)\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if graph the logical program is satisfiable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def satisfiable():\n",
    "    output = subprocess.getoutput(\"clingo logicalprogram.lp 0\")\n",
    "    #print(output)\n",
    "    returnvalue = not \"UNSATISFIABLE\" in output\n",
    "    #print(returnvalue)\n",
    "    #print(output)\n",
    "    return returnvalue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script should receive a graph (dictionary) and a sequence (list) and it will return true or false whether the graph can implement the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_check(sequence, graph):\n",
    "    writeaxioms(graph) #write the initial axioms\n",
    "    addinputsOR(graph) #add the required input constraints for nodes\n",
    "    addsequencefromlist(sequence) #add the sequence that has to be verified\n",
    "    return satisfiable() #check that the file accepts the graph currently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "\n",
    "unused_graph_test = [    \n",
    "    {\"Node\": 1, \"Edges\": [5], \"Processed\": False, \"Inputs\": []},\n",
    "    {\"Node\": 5, \"Edges\": [8], \"Processed\": False, \"Inputs\": [1]},\n",
    "    {\"Node\": 8, \"Edges\": [2], \"Processed\": False, \"Inputs\": [5]},\n",
    "    {\"Node\": 2, \"Edges\": [3], \"Processed\": False, \"Inputs\": [8,4]},\n",
    "    {\"Node\": 3, \"Edges\": [6], \"Processed\": False, \"Inputs\": [2]},\n",
    "    {\"Node\": 6, \"Edges\": [9,4,11], \"Processed\": False, \"Inputs\": [3]},\n",
    "    {\"Node\": 4, \"Edges\": [2], \"Processed\": False, \"Inputs\": [9,6]},\n",
    "    {\"Node\": 11, \"Edges\": [], \"Processed\": False, \"Inputs\": [6]},\n",
    "    {\"Node\": 9, \"Edges\": [4], \"Processed\": False, \"Inputs\": [6]},\n",
    "    ]\n",
    "\n",
    "#sequence_test = [\"G11\",\"G5\",\"G8\",\"G2\",\"G3\",\"G6\",\"G1\"]\n",
    "\n",
    "#print(sequence_check(sequence_test, unusued_graph_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of sequences into the sequencelist variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencelist = []\n",
    "\n",
    "\n",
    "sequence_test = [\"GS\", \"G4\", \"G1\",\"G5\",\"G5\",\"G8\",\"G2\",\"G3\",\"G6\",\"G1\",\"GF\"]\n",
    "\n",
    "sequencelist = sequence_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the graph into a graph list of dictionares of form [ {Node: int, Edges: [int], Processed: bool, Inputs [int]} ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = []\n",
    "\n",
    "graph_2 = [\n",
    "    {\"Node\": \"S\", \"Edges\": [\"1\"], \"Processed\": False, \"Inputs\": []},\n",
    "    {\"Node\": \"1\", \"Edges\": [\"5\"], \"Processed\": False, \"Inputs\": [\"S\"]},\n",
    "    {\"Node\": \"5\", \"Edges\": [\"8\"], \"Processed\": False, \"Inputs\": [\"1\"]},\n",
    "    {\"Node\": \"8\", \"Edges\": [\"2\"], \"Processed\": False, \"Inputs\": [\"5\"]},\n",
    "    {\"Node\": \"2\", \"Edges\": [\"3\"], \"Processed\": False, \"Inputs\": [\"8\",\"4\"]},\n",
    "    {\"Node\": \"3\", \"Edges\": [\"6\"], \"Processed\": False, \"Inputs\": [\"2\"]},\n",
    "    {\"Node\": \"6\", \"Edges\": [\"9\",\"4\",\"11\"], \"Processed\": False, \"Inputs\": [\"3\"]},\n",
    "    {\"Node\": \"4\", \"Edges\": [\"2\"], \"Processed\": False, \"Inputs\": [\"9\",\"6\"]},\n",
    "    {\"Node\": \"11\", \"Edges\": [\"F\"], \"Processed\": False, \"Inputs\": [\"6\"]},\n",
    "    {\"Node\": \"9\", \"Edges\": [\"4\"], \"Processed\": False, \"Inputs\": [\"6\"]},\n",
    "    {\"Node\": \"F\", \"Edges\": [], \"Processed\": False, \"Inputs\": [\"11\"]},\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "graph_1 = [\n",
    "    {\"Node\": \"S\", \"Edges\": [\"1\"], \"Processed\": False, \"Inputs\": []},\n",
    "    {\"Node\": \"1\", \"Edges\": [\"5\"], \"Processed\": False, \"Inputs\": [\"S\"]},\n",
    "    {\"Node\": \"5\", \"Edges\": [\"8\"], \"Processed\": False, \"Inputs\": [\"1\"]},\n",
    "    {\"Node\": \"8\", \"Edges\": [\"2\"], \"Processed\": False, \"Inputs\": [\"5\"]},\n",
    "    {\"Node\": \"2\", \"Edges\": [\"3\"], \"Processed\": False, \"Inputs\": [\"8\",\"4\"]},\n",
    "    {\"Node\": \"3\", \"Edges\": [\"6\"], \"Processed\": False, \"Inputs\": [\"2\"]},\n",
    "    {\"Node\": \"6\", \"Edges\": [\"4\",\"11\"], \"Processed\": False, \"Inputs\": [\"3\"]},\n",
    "    {\"Node\": \"4\", \"Edges\": [\"2\"], \"Processed\": False, \"Inputs\": [\"6\"]},\n",
    "    {\"Node\": \"11\", \"Edges\": [\"F\"], \"Processed\": False, \"Inputs\": [\"6\"]},\n",
    "    {\"Node\": \"F\", \"Edges\": [], \"Processed\": False, \"Inputs\": [\"11\"]},\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "graph_3 = [\n",
    "    {\"Node\": \"S\", \"Edges\": [\"1\"], \"Processed\": False, \"Inputs\": []},\n",
    "    {\"Node\": \"1\", \"Edges\": [\"5\"], \"Processed\": False, \"Inputs\": [\"S\"]},\n",
    "    {\"Node\": \"5\", \"Edges\": [\"8\"], \"Processed\": False, \"Inputs\": [\"1\"]},\n",
    "    {\"Node\": \"8\", \"Edges\": [\"2\"], \"Processed\": False, \"Inputs\": [\"5\"]},\n",
    "    {\"Node\": \"2\", \"Edges\": [\"3\"], \"Processed\": False, \"Inputs\": [\"8\",\"4\"]},\n",
    "    {\"Node\": \"3\", \"Edges\": [\"6\"], \"Processed\": False, \"Inputs\": [\"2\"]},\n",
    "    {\"Node\": \"6\", \"Edges\": [\"9\",\"11\"], \"Processed\": False, \"Inputs\": [\"3\"]},\n",
    "    {\"Node\": \"4\", \"Edges\": [\"2\"], \"Processed\": False, \"Inputs\": [\"9\"]},\n",
    "    {\"Node\": \"11\", \"Edges\": [\"F\"], \"Processed\": False, \"Inputs\": [\"6\"]},\n",
    "    {\"Node\": \"9\", \"Edges\": [\"4\"], \"Processed\": False, \"Inputs\": [\"6\"]},\n",
    "    {\"Node\": \"F\", \"Edges\": [], \"Processed\": False, \"Inputs\": [\"11\"]},\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "graph = unused_graph_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a loop that goes through a list and a given graph and for each list entry checks satisfiability, if true - the element goes into the list of accepted elements, if false - the element goes into a list of not accepted elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_two_lists(sequencelist,graph):\n",
    "    acceptedlist = []\n",
    "    notacceptedlist = []\n",
    "    allowednodes = []\n",
    "    for dictitem in graph:\n",
    "        allowednodes.append('G' + dictitem[\"Node\"])\n",
    "    #print(allowednodes)\n",
    "\n",
    "    for i in sequencelist:\n",
    "        if i in allowednodes:\n",
    "            acceptedlist.append(i)\n",
    "            #print(acceptedlist)\n",
    "            if sequence_check(acceptedlist, graph):\n",
    "                unusedvariable = 0\n",
    "            else: \n",
    "                acceptedlist.pop()\n",
    "                notacceptedlist.append(i)\n",
    "        else:\n",
    "            notacceptedlist.append(i)\n",
    "        \n",
    "    return [acceptedlist,notacceptedlist]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing function\n",
    "# #print(get_two_lists(sequencelist,graph_1))\n",
    "#print(get_two_lists(sequencelist,graph_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#make a list of disctionaries of sequences\n",
    "seqlist = []\n",
    "with open('suturing_file_sequences.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        seqlist.append({\"sequence\": row})\n",
    "\n",
    "\n",
    "#make a list of dictionaries of filename\n",
    "filelist = []\n",
    "with open('suturing_files.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        stringarray = \"\"\n",
    "        for i in row:\n",
    "            stringarray = stringarray + i\n",
    "        #print(stringarray)\n",
    "        filelist.append({\"filename\": stringarray})\n",
    "\n",
    "#print(filelist)\n",
    "\n",
    "#merge two lists of dictionaries\n",
    "for i in range (len(filelist)):\n",
    "    seqlist[i][\"filename\"] = filelist[i][\"filename\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function for adding starting and ending nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_end(seqlist):\n",
    "    seqlist.insert(0,\"GS\")\n",
    "    seqlist.append(\"GF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_start_end(seqlist[10][\"sequence\"])\n",
    "#print(seqlist[10][\"sequence\"])\n",
    "#print(get_two_lists(seqlist[10][\"sequence\"],graph_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "7\n",
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "graph1counter = 0\n",
    "graph2counter = 0\n",
    "graph3counter = 0\n",
    "avg1 = []\n",
    "avg2 = []\n",
    "avg3 = []\n",
    "oavg1 = []\n",
    "oavg2 = []\n",
    "oavg3 = []\n",
    "check1and2 = 0\n",
    "check1and3 = 0\n",
    "check2and3 = 0\n",
    "heck1and2and3 = 0\n",
    "graph1_acc_list = []\n",
    "graph2_acc_list = []\n",
    "graph3_acc_list = []\n",
    "\n",
    "#print(get_two_lists(seqlist[11][\"sequence\"],graph_1))\n",
    "\n",
    "for listitem in seqlist:\n",
    "\n",
    "#    graph1counter = graph1counter + 1\n",
    "#    #print(add_start_end(listitem[\"sequence\"]))\n",
    "    add_start_end(listitem[\"sequence\"])\n",
    "#    #print(listitem[\"sequence\"])\n",
    "#    print(\"graph 1 lists\")\n",
    "#    #print(get_two_lists(listitem[\"sequence\"],graph_1)[0])\n",
    "    seq1 = get_two_lists(listitem[\"sequence\"],graph_1)\n",
    "#    print(listitem)\n",
    "#    print(seq1)\n",
    "   \n",
    "   \n",
    "    if seq1[0][-1] == \"GF\" and len(seq1[1]) == 0:\n",
    "       graph1counter = graph1counter + 1\n",
    "       #avg1.append(len(seq1[1])/(len(seq1[0]) + len(seq1[1])))\n",
    "\n",
    "\n",
    "#    #avg1.append(len(seq1[0])/(len(seq1[0]) + len(seq1[1])))\n",
    "   \n",
    "   \n",
    "   \n",
    "    if seq1[0][-1] == \"GF\":\n",
    "       graph1_acc_list.append(1)\n",
    "    else:\n",
    "       graph1_acc_list.append(0)\n",
    "\n",
    "\n",
    "   #    #graph1counter = graph1counter + 1\n",
    "   #    #avg1.append(len(get_two_lists(listitem[\"sequence\"],graph_1)[0])/(len(get_two_lists(listitem[\"sequence\"],graph_1)[0]) + len(get_two_lists(listitem[\"sequence\"],graph_1)[1])))\n",
    "\n",
    "   # #print(\"graph 2 lists\")\n",
    "   # #print(get_two_lists(listitem[\"sequence\"],graph_2)[0])\n",
    "    seq2 = get_two_lists(listitem[\"sequence\"],graph_2)\n",
    "    if seq2[0][-1] == \"GF\" and len(seq2[1]) == 0:\n",
    "       #avg2.append(len(seq2[1])/(len(seq2[0]) + len(seq2[1])))\n",
    "      graph2counter = graph2counter + 1\n",
    "\n",
    "\n",
    "\n",
    "    if seq2[0][-1] == \"GF\":\n",
    "       graph2_acc_list.append(1)\n",
    "    else:\n",
    "       graph2_acc_list.append(0)\n",
    "\n",
    "   # # if seq2[0][-1] != \"GF\":\n",
    "   # #    graph1counter = graph1counter + 1\n",
    "   # #    avg2.append(len(get_two_lists(listitem[\"sequence\"],graph_2)[1])/(len(get_two_lists(listitem[\"sequence\"],graph_2)[0]) + len(get_two_lists(listitem[\"sequence\"],graph_2)[1])))\n",
    "\n",
    "   # #print(\"graph 3 lists\")\n",
    "   # #print(get_two_lists(listitem[\"sequence\"],graph_3)[0])\n",
    "    seq3 = get_two_lists(listitem[\"sequence\"],graph_3)\n",
    "    if seq3[0][-1] == \"GF\"  and len(seq3[1]) == 0:\n",
    "      graph3counter = graph3counter + 1\n",
    "      #avg3.append(len(seq3[1])/(len(seq3[0]) + len(seq3[1])))\n",
    "       \n",
    "   \n",
    "   \n",
    "    if seq3[0][-1] == \"GF\":\n",
    "       graph3_acc_list.append(1)\n",
    "    else:\n",
    "       graph3_acc_list.append(0)\n",
    "\n",
    "   # if seq3[0][-1] != \"GF\":\n",
    "   #    graph1counter = graph1counter + 1\n",
    "   #    avg3.append(len(get_two_lists(listitem[\"sequence\"],graph_3)[1])/(len(get_two_lists(listitem[\"sequence\"],graph_3)[0]) + len(get_two_lists(listitem[\"sequence\"],graph_3)[1])))\n",
    "\n",
    "\n",
    "#    if seq1[0][-1] != \"GF\":\n",
    "#       print(\"sequence accepted by 1\")\n",
    "#       unusedvariable = 0\n",
    "#       if seq2[0][-1] != \"GF\":\n",
    "      \n",
    "#          check1and2 = check1and2 + 1\n",
    "#          print(\"Sequences accepted by graphs 1 and 2 \", check1and2)\n",
    "#          if seq3[0][-1] != \"GF\":\n",
    "#                check1and2and3 = check1and2and3 + 1\n",
    "#                print(\"Sequences accepted by graphs 1 and 2 and 3 \", check1and2and3)\n",
    "#       if seq3[0][-1] != \"GF\":\n",
    "#          check1and3 = check1and3 + 1\n",
    "#          print(\"Sequences accepted by graphs 1 and 3 \", check1and3)\n",
    "   \n",
    "#    if seq3[0][-1] != \"GF\":\n",
    "#       print(\"sequence accepted by 3\")\n",
    "#       if seq2[0][-1] != \"GF\":\n",
    "#          check2and3 = check2and3 + 1\n",
    "#          print(\"Sequences accepted by graphs 2 and 3 \", check2and3)\n",
    "\n",
    "# print(\"Sequences rejected by graphs 1 and 2 \", check1and2)\n",
    "# print(\"Sequences rejected by graphs 1 and 3 \", check1and3)\n",
    "# print(\"Sequences rejected by graphs 2 and 3 \", check2and3)\n",
    "# print(\"Sequences rejected by graphs 1 and 2 and 3 \", check1and2and3)\n",
    "#print(avg1, ' ', avg2, ' ', avg3, ' ')\n",
    "\n",
    "\n",
    "print(graph1_acc_list)\n",
    "print(graph2_acc_list)\n",
    "print(graph3_acc_list)\n",
    "\n",
    "print(graph1counter)\n",
    "print(graph2counter)\n",
    "print(graph3counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 and 2  18 1 and 3  18 2 and 3  18 1 and 2 and 3  18\n",
      "1 and 2  19 1 and 3  18 2 and 3  20 1 and 2 and 3  18\n",
      "mean 1  0.5128205128205128\n",
      "mean 2 0.46153846153846156\n",
      "mean3  0.48717948717948717\n",
      "mean all:  0.48717948717948717\n"
     ]
    }
   ],
   "source": [
    "yes1and2acc = 0\n",
    "yes1and3acc = 0\n",
    "yes2and3acc = 0\n",
    "yes2and3acc = 0\n",
    "yes1and2and3acc = 0\n",
    "no1and2acc = 0\n",
    "no1and3acc = 0\n",
    "no2and3acc = 0\n",
    "no2and3acc = 0\n",
    "no1and2and3acc = 0\n",
    "\n",
    "for i in range(0,len(graph1_acc_list)):\n",
    "    if graph1_acc_list[i] == graph2_acc_list[i] == 1:\n",
    "        yes1and2acc = yes1and2acc + 1\n",
    "    if graph1_acc_list[i] == graph3_acc_list[i] == 1:\n",
    "        yes1and3acc = yes1and3acc + 1\n",
    "    if graph2_acc_list[i] == graph3_acc_list[i] == 1:\n",
    "        yes2and3acc = yes2and3acc + 1\n",
    "    if graph1_acc_list[i] == graph2_acc_list[i] == graph3_acc_list[i] == 1:\n",
    "        yes1and2and3acc = yes1and2and3acc + 1 \n",
    "    \n",
    "    if graph1_acc_list[i] == graph2_acc_list[i] == 0:\n",
    "        no1and2acc = no1and2acc + 1\n",
    "    if graph1_acc_list[i] == graph3_acc_list[i] == 0:\n",
    "        no1and3acc = no1and3acc + 1\n",
    "    if graph2_acc_list[i] == graph3_acc_list[i] == 0:\n",
    "        no2and3acc = no2and3acc + 1\n",
    "    if graph1_acc_list[i] == graph2_acc_list[i] == graph3_acc_list[i] == 0:\n",
    "        no1and2and3acc = no1and2and3acc + 1 \n",
    "\n",
    "\n",
    "print('1 and 2 ', yes1and2acc, '1 and 3 ', yes1and3acc, \"2 and 3 \", yes2and3acc, \"1 and 2 and 3 \", yes1and2and3acc)\n",
    "print('1 and 2 ', no1and2acc, '1 and 3 ', no1and3acc, \"2 and 3 \", no2and3acc, \"1 and 2 and 3 \", no1and2and3acc)\n",
    "\n",
    "print(\"mean 1 \", sum(graph1_acc_list)/39)\n",
    "print(\"mean 2\", sum(graph2_acc_list)/39)\n",
    "print(\"mean3 \", sum(graph3_acc_list)/39)\n",
    "print(\"mean all: \", (sum(graph1_acc_list) + sum(graph2_acc_list) + sum(graph3_acc_list))/(3*39)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "ename": "StatisticsError",
     "evalue": "mean requires at least one data point",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[255], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstatistics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(mean(avg1), mean(avg2), mean(avg3), (mean(avg1) \u001b[39m+\u001b[39m mean(avg2) \u001b[39m+\u001b[39m mean(avg3))\u001b[39m/\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\NS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\statistics.py:432\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    430\u001b[0m T, total, n \u001b[39m=\u001b[39m _sum(data)\n\u001b[0;32m    431\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 432\u001b[0m     \u001b[39mraise\u001b[39;00m StatisticsError(\u001b[39m'\u001b[39m\u001b[39mmean requires at least one data point\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    433\u001b[0m \u001b[39mreturn\u001b[39;00m _convert(total \u001b[39m/\u001b[39m n, T)\n",
      "\u001b[1;31mStatisticsError\u001b[0m: mean requires at least one data point"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "print(mean(avg1), mean(avg2), mean(avg3), (mean(avg1) + mean(avg2) + mean(avg3))/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "[0.3225806451612903, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.045454545454545456, 0.125, 0.19230769230769232, 0.16, 0.35, 0.0, 0.25, 0.045454545454545456, 0.125, 0.045454545454545456, 0.0, 0.15, 0.08695652173913043, 0.0] [0.3225806451612903, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.045454545454545456, 0.0, 0.35, 0.0, 0.25, 0.0, 0.08333333333333333, 0.045454545454545456, 0.0, 0.15, 0.08695652173913043, 0.0] [0.7096774193548387, 0.5714285714285714, 0.5714285714285714, 0.5909090909090909, 0.5714285714285714, 0.5714285714285714, 0.5909090909090909, 0.0, 0.55, 0.55, 0.5714285714285714, 0.6785714285714286, 0.36363636363636365, 0.20833333333333334, 0.5909090909090909, 0.5714285714285714, 0.55, 0.6086956521739131, 0.5714285714285714]\n"
     ]
    }
   ],
   "source": [
    "print(graph1_acc_list)\n",
    "print(graph2_acc_list)\n",
    "print(graph3_acc_list)\n",
    "print(avg1,avg2,avg3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
